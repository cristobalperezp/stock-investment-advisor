{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "663f1efb",
   "metadata": {},
   "source": [
    "# üè† Price Predictor - Boston Housing Demo\n",
    "\n",
    "Este notebook demuestra las capacidades del sistema Price Predictor para la predicci√≥n de precios de viviendas.\n",
    "\n",
    "## üìã Contenido\n",
    "1. Carga y exploraci√≥n de datos\n",
    "2. An√°lisis exploratorio\n",
    "3. Preprocesamiento\n",
    "4. Entrenamiento de modelos\n",
    "5. Evaluaci√≥n y comparaci√≥n\n",
    "6. Predicciones de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30e762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Configuraci√≥n de gr√°ficos\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üìö Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0dc32e",
   "metadata": {},
   "source": [
    "## 1. üìä Carga y Exploraci√≥n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f1a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset Boston Housing\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Cargar datos\n",
    "boston = load_boston()\n",
    "\n",
    "# Crear DataFrame\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['MEDV'] = boston.target  # Precio objetivo\n",
    "\n",
    "print(f\"üìà Dataset cargado: {df.shape[0]} filas, {df.shape[1]} columnas\")\n",
    "print(f\"üéØ Variable objetivo: MEDV (precio medio en miles de $)\")\n",
    "\n",
    "# Mostrar primeras filas\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informaci√≥n b√°sica del dataset\n",
    "print(\"üìã INFORMACI√ìN DEL DATASET\")\n",
    "print(\"=\" * 50)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92246948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estad√≠sticas descriptivas\n",
    "print(\"üìä ESTAD√çSTICAS DESCRIPTIVAS\")\n",
    "print(\"=\" * 50)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e7228",
   "metadata": {},
   "source": [
    "## 2. üîç An√°lisis Exploratorio de Datos (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e554f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuci√≥n de la variable objetivo\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Histograma\n",
    "axes[0].hist(df['MEDV'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "axes[0].set_title('Distribuci√≥n de Precios (MEDV)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Precio (miles de $)')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "axes[1].boxplot(df['MEDV'], patch_artist=True, \n",
    "                boxprops=dict(facecolor='lightcoral', alpha=0.7))\n",
    "axes[1].set_title('Box Plot de Precios (MEDV)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('Precio (miles de $)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠sticas de la variable objetivo\n",
    "print(f\"üìä Precio promedio: ${df['MEDV'].mean():.1f}k\")\n",
    "print(f\"üìä Precio mediano: ${df['MEDV'].median():.1f}k\")\n",
    "print(f\"üìä Rango: ${df['MEDV'].min():.1f}k - ${df['MEDV'].max():.1f}k\")\n",
    "print(f\"üìä Desviaci√≥n est√°ndar: ${df['MEDV'].std():.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ce8136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlaci√≥n interactiva\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Crear heatmap con Plotly\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=correlation_matrix.values,\n",
    "    x=correlation_matrix.columns,\n",
    "    y=correlation_matrix.columns,\n",
    "    colorscale='RdYlBu_r',\n",
    "    zmid=0,\n",
    "    text=correlation_matrix.round(2).values,\n",
    "    texttemplate=\"%{text}\",\n",
    "    textfont={\"size\": 10},\n",
    "    hovertemplate='%{x} vs %{y}<br>Correlaci√≥n: %{z:.3f}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='üî• Matriz de Correlaci√≥n - Boston Housing',\n",
    "    width=800,\n",
    "    height=600,\n",
    "    xaxis_title='Variables',\n",
    "    yaxis_title='Variables'\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# Variables m√°s correlacionadas con MEDV\n",
    "print(\"üéØ CORRELACIONES CON PRECIO (MEDV)\")\n",
    "print(\"=\" * 40)\n",
    "correlations_with_target = correlation_matrix['MEDV'].drop('MEDV').sort_values(key=abs, ascending=False)\n",
    "for var, corr in correlations_with_target.head(5).items():\n",
    "    print(f\"{var:>8}: {corr:>6.3f} {'üìà' if corr > 0 else 'üìâ'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6682fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots de las variables m√°s importantes\n",
    "important_vars = ['RM', 'LSTAT', 'PTRATIO', 'TAX']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, var in enumerate(important_vars):\n",
    "    correlation = df[var].corr(df['MEDV'])\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[i].scatter(df[var], df['MEDV'], alpha=0.6, color=f'C{i}')\n",
    "    \n",
    "    # L√≠nea de tendencia\n",
    "    z = np.polyfit(df[var], df['MEDV'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[i].plot(df[var], p(df[var]), \"r--\", alpha=0.8, linewidth=2)\n",
    "    \n",
    "    axes[i].set_xlabel(var)\n",
    "    axes[i].set_ylabel('MEDV (Precio)')\n",
    "    axes[i].set_title(f'{var} vs MEDV\\nCorrelaci√≥n: {correlation:.3f}')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4919838d",
   "metadata": {},
   "source": [
    "## 3. üîß Preprocesamiento de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9929d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separar features y target\n",
    "X = df.drop('MEDV', axis=1)\n",
    "y = df['MEDV']\n",
    "\n",
    "print(f\"üìä Features: {X.shape[1]} variables\")\n",
    "print(f\"üìä Muestras: {X.shape[0]} viviendas\")\n",
    "\n",
    "# Divisi√≥n de datos: train (60%), val (20%), test (20%)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.25, random_state=42  # 0.25 * 0.8 = 0.2\n",
    ")\n",
    "\n",
    "print(f\"\\nüìà DIVISI√ìN DE DATOS:\")\n",
    "print(f\"  Entrenamiento: {X_train.shape[0]} muestras ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  Validaci√≥n:    {X_val.shape[0]} muestras ({X_val.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  Test:          {X_test.shape[0]} muestras ({X_test.shape[0]/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caaeca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar solo con datos de entrenamiento\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train),\n",
    "    columns=X_train.columns,\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_val_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_val),\n",
    "    columns=X_val.columns,\n",
    "    index=X_val.index\n",
    ")\n",
    "\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Datos escalados correctamente\")\n",
    "\n",
    "# Verificar escalado\n",
    "print(f\"\\nüìä VERIFICACI√ìN DEL ESCALADO:\")\n",
    "print(f\"Media entrenamiento: {X_train_scaled.mean().mean():.6f}\")\n",
    "print(f\"Std entrenamiento: {X_train_scaled.std().mean():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc59efc9",
   "metadata": {},
   "source": [
    "## 4. ü§ñ Entrenamiento de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600e12d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import time\n",
    "\n",
    "# Funci√≥n para evaluar modelos\n",
    "def evaluate_model(model, X_val, y_val):\n",
    "    \"\"\"Eval√∫a un modelo y retorna m√©tricas\"\"\"\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    metrics = {\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_val, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_val, y_pred),\n",
    "        'R¬≤': r2_score(y_val, y_pred)\n",
    "    }\n",
    "    \n",
    "    return metrics, y_pred\n",
    "\n",
    "print(\"ü§ñ Entrenando modelos...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Diccionario para almacenar resultados\n",
    "models = {}\n",
    "results = {}\n",
    "\n",
    "# 1. Random Forest\n",
    "print(\"üå≤ Entrenando Random Forest...\")\n",
    "start_time = time.time()\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "rf_metrics, rf_pred = evaluate_model(rf_model, X_val_scaled, y_val)\n",
    "rf_time = time.time() - start_time\n",
    "\n",
    "models['Random Forest'] = rf_model\n",
    "results['Random Forest'] = {**rf_metrics, 'Time': rf_time}\n",
    "\n",
    "print(f\"  ‚úÖ Completado en {rf_time:.2f}s\")\n",
    "print(f\"  üìä RMSE: {rf_metrics['RMSE']:.3f}\")\n",
    "print(f\"  üìä R¬≤: {rf_metrics['R¬≤']:.3f}\")\n",
    "\n",
    "# 2. LightGBM\n",
    "print(\"\\n‚ö° Entrenando LightGBM...\")\n",
    "start_time = time.time()\n",
    "\n",
    "lgb_model = LGBMRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    verbosity=-1\n",
    ")\n",
    "lgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "lgb_metrics, lgb_pred = evaluate_model(lgb_model, X_val_scaled, y_val)\n",
    "lgb_time = time.time() - start_time\n",
    "\n",
    "models['LightGBM'] = lgb_model\n",
    "results['LightGBM'] = {**lgb_metrics, 'Time': lgb_time}\n",
    "\n",
    "print(f\"  ‚úÖ Completado en {lgb_time:.2f}s\")\n",
    "print(f\"  üìä RMSE: {lgb_metrics['RMSE']:.3f}\")\n",
    "print(f\"  üìä R¬≤: {lgb_metrics['R¬≤']:.3f}\")\n",
    "\n",
    "# 3. Linear Regression\n",
    "print(\"\\nüìà Entrenando Linear Regression...\")\n",
    "start_time = time.time()\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "lr_metrics, lr_pred = evaluate_model(lr_model, X_val_scaled, y_val)\n",
    "lr_time = time.time() - start_time\n",
    "\n",
    "models['Linear Regression'] = lr_model\n",
    "results['Linear Regression'] = {**lr_metrics, 'Time': lr_time}\n",
    "\n",
    "print(f\"  ‚úÖ Completado en {lr_time:.2f}s\")\n",
    "print(f\"  üìä RMSE: {lr_metrics['RMSE']:.3f}\")\n",
    "print(f\"  üìä R¬≤: {lr_metrics['R¬≤']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c5bdac",
   "metadata": {},
   "source": [
    "## 5. üìä Evaluaci√≥n y Comparaci√≥n de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2147ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame de resultados\n",
    "results_df = pd.DataFrame(results).T\n",
    "results_df = results_df.round(3)\n",
    "\n",
    "print(\"üèÜ COMPARACI√ìN DE MODELOS\")\n",
    "print(\"=\" * 50)\n",
    "print(results_df.to_string())\n",
    "\n",
    "# Identificar mejor modelo\n",
    "best_model_name = results_df['RMSE'].idxmin()\n",
    "best_rmse = results_df.loc[best_model_name, 'RMSE']\n",
    "best_r2 = results_df.loc[best_model_name, 'R¬≤']\n",
    "\n",
    "print(f\"\\nü•á MEJOR MODELO: {best_model_name}\")\n",
    "print(f\"   RMSE: {best_rmse:.3f}\")\n",
    "print(f\"   R¬≤: {best_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70974003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de comparaci√≥n\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "metrics = ['RMSE', 'MAE', 'R¬≤']\n",
    "colors = ['coral', 'skyblue', 'lightgreen']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = results_df[metric].values\n",
    "    models_names = results_df.index\n",
    "    \n",
    "    bars = axes[i].bar(models_names, values, color=colors[i], alpha=0.7, edgecolor='black')\n",
    "    axes[i].set_title(f'{metric} por Modelo', fontsize=14, fontweight='bold')\n",
    "    axes[i].set_ylabel(metric)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # A√±adir valores en las barras\n",
    "    for bar, value in zip(bars, values):\n",
    "        height = bar.get_height()\n",
    "        axes[i].text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                    f'{value:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Rotar etiquetas del eje x\n",
    "    axes[i].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d62686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gr√°fico de predicciones vs valores reales\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "predictions = {\n",
    "    'Random Forest': rf_pred,\n",
    "    'LightGBM': lgb_pred,\n",
    "    'Linear Regression': lr_pred\n",
    "}\n",
    "\n",
    "for i, (model_name, y_pred) in enumerate(predictions.items()):\n",
    "    # Scatter plot\n",
    "    axes[i].scatter(y_val, y_pred, alpha=0.6, color=f'C{i}')\n",
    "    \n",
    "    # L√≠nea perfecta (y = x)\n",
    "    min_val = min(y_val.min(), y_pred.min())\n",
    "    max_val = max(y_val.max(), y_pred.max())\n",
    "    axes[i].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, alpha=0.8)\n",
    "    \n",
    "    # Configuraci√≥n\n",
    "    axes[i].set_xlabel('Valores Reales')\n",
    "    axes[i].set_ylabel('Predicciones')\n",
    "    axes[i].set_title(f'{model_name}\\nR¬≤ = {results[model_name][\"R¬≤\"]:.3f}')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # A√±adir l√≠mites iguales\n",
    "    axes[i].set_xlim([min_val, max_val])\n",
    "    axes[i].set_ylim([min_val, max_val])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7339bcc",
   "metadata": {},
   "source": [
    "## 6. üîç An√°lisis de Importancia de Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16384c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance para modelos que la soportan\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Random Forest\n",
    "rf_importances = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "axes[0].barh(rf_importances['feature'], rf_importances['importance'], color='forestgreen', alpha=0.7)\n",
    "axes[0].set_title('Random Forest - Importancia de Features', fontweight='bold')\n",
    "axes[0].set_xlabel('Importancia')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# LightGBM\n",
    "lgb_importances = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': lgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=True)\n",
    "\n",
    "axes[1].barh(lgb_importances['feature'], lgb_importances['importance'], color='purple', alpha=0.7)\n",
    "axes[1].set_title('LightGBM - Importancia de Features', fontweight='bold')\n",
    "axes[1].set_xlabel('Importancia')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Top features\n",
    "print(\"üéØ TOP 5 FEATURES M√ÅS IMPORTANTES\")\n",
    "print(\"=\" * 40)\n",
    "print(\"\\nRandom Forest:\")\n",
    "for _, row in rf_importances.tail(5).iterrows():\n",
    "    print(f\"  {row['feature']:>8}: {row['importance']:.3f}\")\n",
    "    \n",
    "print(\"\\nLightGBM:\")\n",
    "for _, row in lgb_importances.tail(5).iterrows():\n",
    "    print(f\"  {row['feature']:>8}: {row['importance']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8030dcea",
   "metadata": {},
   "source": [
    "## 7. üéØ Ejemplos de Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b104929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar mejor modelo\n",
    "best_model = models[best_model_name]\n",
    "print(f\"ü•á Usando el mejor modelo: {best_model_name}\")\n",
    "\n",
    "# Ejemplos de predicciones\n",
    "sample_indices = [0, 50, 100, 150, 200]\n",
    "samples = X_test.iloc[sample_indices]\n",
    "samples_scaled = X_test_scaled.iloc[sample_indices]\n",
    "real_prices = y_test.iloc[sample_indices]\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = best_model.predict(samples_scaled)\n",
    "\n",
    "print(\"\\nüè† EJEMPLOS DE PREDICCIONES\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Muestra':>8} {'Real':>10} {'Predicho':>10} {'Error':>10} {'Error%':>8}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for i, (idx, real, pred) in enumerate(zip(sample_indices, real_prices, predictions)):\n",
    "    error = abs(real - pred)\n",
    "    error_pct = (error / real) * 100\n",
    "    \n",
    "    print(f\"{i+1:>8} {real:>10.1f} {pred:>10.1f} {error:>10.1f} {error_pct:>7.1f}%\")\n",
    "\n",
    "# Estad√≠sticas de error\n",
    "mean_error_pct = np.mean([abs(r-p)/r*100 for r, p in zip(real_prices, predictions)])\n",
    "print(f\"\\nüìä Error promedio: {mean_error_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c72a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una predicci√≥n personalizada\n",
    "print(\"üéØ PREDICCI√ìN PERSONALIZADA\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Ejemplo: Casa con caracter√≠sticas promedio pero con m√°s habitaciones\n",
    "custom_house = pd.DataFrame({\n",
    "    'CRIM': [2.0],      # Criminalidad baja-media\n",
    "    'ZN': [20.0],       # Zona residencial\n",
    "    'INDUS': [8.0],     # Industria moderada\n",
    "    'CHAS': [0],        # No limita con r√≠o\n",
    "    'NOX': [0.45],      # NOX bajo\n",
    "    'RM': [7.5],        # 7.5 habitaciones (m√°s que promedio)\n",
    "    'AGE': [30.0],      # Casa relativamente nueva\n",
    "    'DIS': [6.0],       # Distancia media a centros\n",
    "    'RAD': [5.0],       # Accesibilidad media\n",
    "    'TAX': [250.0],     # Impuestos moderados\n",
    "    'PTRATIO': [16.0],  # Ratio alumno-profesor bueno\n",
    "    'B': [380.0],       # B alto\n",
    "    'LSTAT': [8.0]      # Estatus socioecon√≥mico alto\n",
    "})\n",
    "\n",
    "# Escalar\n",
    "custom_house_scaled = pd.DataFrame(\n",
    "    scaler.transform(custom_house),\n",
    "    columns=custom_house.columns\n",
    ")\n",
    "\n",
    "# Predicci√≥n\n",
    "custom_prediction = best_model.predict(custom_house_scaled)[0]\n",
    "\n",
    "print(\"Caracter√≠sticas de la casa:\")\n",
    "print(f\"  üè† Habitaciones: {custom_house.iloc[0]['RM']} (promedio: {df['RM'].mean():.1f})\")\n",
    "print(f\"  üöî Criminalidad: {custom_house.iloc[0]['CRIM']} (promedio: {df['CRIM'].mean():.1f})\")\n",
    "print(f\"  üìö Ratio estudiante-profesor: {custom_house.iloc[0]['PTRATIO']} (promedio: {df['PTRATIO'].mean():.1f})\")\n",
    "print(f\"  üìä Estatus bajo (%): {custom_house.iloc[0]['LSTAT']} (promedio: {df['LSTAT'].mean():.1f})\")\n",
    "\n",
    "print(f\"\\nüí∞ Precio predicho: ${custom_prediction:.1f}k\")\n",
    "print(f\"üí∞ Precio promedio dataset: ${df['MEDV'].mean():.1f}k\")\n",
    "print(f\"üí∞ Diferencia: ${custom_prediction - df['MEDV'].mean():.1f}k ({((custom_prediction/df['MEDV'].mean()-1)*100):+.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a60452a",
   "metadata": {},
   "source": [
    "## üéâ Conclusiones\n",
    "\n",
    "### üìä Resultados del An√°lisis:\n",
    "\n",
    "1. **Dataset**: 506 viviendas con 13 caracter√≠sticas predictoras\n",
    "2. **Mejor modelo**: Determinado por menor RMSE\n",
    "3. **Features importantes**: RM (habitaciones), LSTAT (estatus), PTRATIO (educaci√≥n)\n",
    "4. **Rendimiento**: R¬≤ > 0.8 indica buena capacidad predictiva\n",
    "\n",
    "### üöÄ Pr√≥ximos Pasos:\n",
    "\n",
    "- **Optimizaci√≥n de hiperpar√°metros** con Optuna\n",
    "- **Validaci√≥n cruzada** para mayor robustez\n",
    "- **Feature engineering** para mejorar predicciones\n",
    "- **Despliegue** en aplicaci√≥n Streamlit\n",
    "\n",
    "### üí° Insights Clave:\n",
    "\n",
    "- El **n√∫mero de habitaciones (RM)** es el factor m√°s importante\n",
    "- El **estatus socioecon√≥mico (LSTAT)** tiene fuerte correlaci√≥n negativa\n",
    "- Los modelos ensemble (RF, LightGBM) superan a Linear Regression\n",
    "- La **calidad educativa (PTRATIO)** influye significativamente en precios"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
